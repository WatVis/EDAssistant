{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-freight",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json(\"../doc2vec/data/all-notebooks-tokenized.json\", orient='index')\n",
    "import numpy as np\n",
    "embeds2d = np.load(\"../doc2vec/data/notebooks-doc2vec-vectors-apr24.npy\",allow_pickle=True)\n",
    "embeds1d = []\n",
    "for row in embeds2d:\n",
    "    for vecs in row:\n",
    "        embeds1d.append(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empirical-indicator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856941"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.cell_type==\"code\"]\n",
    "len(embeds1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "absent-stations",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': []}\n",
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': ['\\n']}\n",
      "Input is \n",
      "\n",
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': []}\n",
      "[torch.Size([768])]\n",
      "Raw idx is 38587\n",
      "Raw idx is 128494\n",
      "Raw idx is 472501\n",
      "Raw idx is 541646\n",
      "Raw idx is 139434\n",
      "Raw idx is 135774\n",
      "Raw idx is 546369\n",
      "Raw idx is 599976\n",
      "Raw idx is 540825\n",
      "Raw idx is 534707\n",
      "[cell_type                                                        code\n",
      "source              d = run_length(mask.T.ravel())\\n nmask = {}\\n ...\n",
      "filename                                                     18620591\n",
      "competition                          severstal-steel-defect-detection\n",
      "tokenized_source    [d, =, run_length, (, mask, ., T, ., ravel, (,...\n",
      "Name: 52818, dtype: object, cell_type                                                        code\n",
      "source              # # est. weights\\n \\n # def objective(w, i):\\n...\n",
      "filename                                                     46986735\n",
      "competition                                                  lish-moa\n",
      "tokenized_source    [# # est. weights, [NEWLINE], [NEWLINE], # def...\n",
      "Name: 173710, dtype: object, cell_type                                                        code\n",
      "source              # Final check on the new dataset\\n print('Trai...\n",
      "filename                                                     35639945\n",
      "competition                    rsna-intracranial-hemorrhage-detection\n",
      "tokenized_source    [# Final check on the new dataset, [NEWLINE], ...\n",
      "Name: 639575, dtype: object, cell_type                                                        code\n",
      "source              def get_train_and_test(train, test):\\n     com...\n",
      "filename                                                     26460665\n",
      "competition                                    data-science-bowl-2019\n",
      "tokenized_source    [def, get_train_and_test, (, train, ,, test, )...\n",
      "Name: 731652, dtype: object, cell_type                                                        code\n",
      "source              predict = model.predict(test_scaled,num_iterat...\n",
      "filename                                                     39265905\n",
      "competition                        new-york-city-taxi-fare-prediction\n",
      "tokenized_source    [predict, =, model, ., predict, (, test_scaled...\n",
      "Name: 188119, dtype: object, cell_type               code\n",
      "source                      \n",
      "filename            47261563\n",
      "competition         lish-moa\n",
      "tokenized_source          []\n",
      "Name: 183024, dtype: object, cell_type                                                        code\n",
      "source              for i in range(5):\\n     sns.distplot(predicti...\n",
      "filename                                                     27500088\n",
      "competition                                    data-science-bowl-2019\n",
      "tokenized_source    [for, i, in, range, (, 5, ), :, [NEWLINE], [IN...\n",
      "Name: 738044, dtype: object, cell_type                                                        code\n",
      "source              #Custom collate function which takes a batch o...\n",
      "filename                                                      7460896\n",
      "competition                                whats-cooking-kernels-only\n",
      "tokenized_source    [#Custom collate function which takes a batch ...\n",
      "Name: 810712, dtype: object, cell_type                                                        code\n",
      "source              def display(*dfs, head=True):\\n     \"\"\"\\n     ...\n",
      "filename                                                     24694211\n",
      "competition                                    data-science-bowl-2019\n",
      "tokenized_source    [def, display, (, *, dfs, ,, head, =, True, ),...\n",
      "Name: 730540, dtype: object, cell_type                                                        code\n",
      "source              threshold = 0.6*nuclei_brightness/255  # conve...\n",
      "filename                                                     19992747\n",
      "competition                   recursion-cellular-image-classification\n",
      "tokenized_source    [threshold, =, 0.6, *, nuclei_brightness, /, 2...\n",
      "Name: 722408, dtype: object]\n",
      "############################\n",
      "18620591 severstal-steel-defect-detection\n",
      "############################\n",
      "46986735 lish-moa\n",
      "############################\n",
      "35639945 rsna-intracranial-hemorrhage-detection\n",
      "############################\n",
      "26460665 data-science-bowl-2019\n",
      "############################\n",
      "39265905 new-york-city-taxi-fare-prediction\n",
      "############################\n",
      "47261563 lish-moa\n",
      "############################\n",
      "27500088 data-science-bowl-2019\n",
      "############################\n",
      "7460896 whats-cooking-kernels-only\n",
      "############################\n",
      "24694211 data-science-bowl-2019\n",
      "############################\n",
      "19992747 recursion-cellular-image-classification\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': ['import pandas as pd\\n', \"df = pd.read_csv('1.csv')\\n\", 'df.drop()']}\n",
      "Input is import pandas as pd\n",
      "\n",
      "Input is df = pd.read_csv('1.csv')\n",
      "\n",
      "Input is df.drop()\n",
      "\n",
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': ['df.head()\\n', \"index = (data['Region'] == 'Europe') + \\\\\\n\", \"        (data.index == 'United States') + \\\\\\n\", \"        (data.index == 'Canada') + \\\\\\n\", \"        (data.index == 'Mexico')\\n\", 'selected = data[index]\\n', '\\n', 'print \"By Total Gun Homicides\"\\n', 'sys.stdout.flush()\\n', '\\n', 'by_guns = selected.sort(\"Gun Homicides\", ascending=False)\\n', \"#by_guns['Gun Homicides'].plot(kind='bar')\\n\", 'plot_percapita(by_guns, limit=25)\\n', 'display_relevant(selected, limit=None)\\n']}\n",
      "Input is df.head()\n",
      "\n",
      "Input is index = (data['Region'] == 'Europe') + \\\n",
      "\n",
      "Input is         (data.index == 'United States') + \\\n",
      "\n",
      "Input is         (data.index == 'Canada') + \\\n",
      "\n",
      "Input is         (data.index == 'Mexico')\n",
      "\n",
      "Input is selected = data[index]\n",
      "\n",
      "Input is \n",
      "\n",
      "Input is print \"By Total Gun Homicides\"\n",
      "\n",
      "Input is sys.stdout.flush()\n",
      "\n",
      "Input is \n",
      "\n",
      "Input is by_guns = selected.sort(\"Gun Homicides\", ascending=False)\n",
      "\n",
      "Input is #by_guns['Gun Homicides'].plot(kind='bar')\n",
      "\n",
      "Input is plot_percapita(by_guns, limit=25)\n",
      "\n",
      "Input is display_relevant(selected, limit=None)\n",
      "\n",
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': [\"select = data.ix[['United States', 'Canada', 'United Kingdom']]\\n\", 'plot_percapita(select)\\n', 'for country in data.index:\\n', '    print country\\n']}\n",
      "Input is select = data.ix[['United States', 'Canada', 'United Kingdom']]\n",
      "\n",
      "Input is plot_percapita(select)\n",
      "\n",
      "Input is for country in data.index:\n",
      "\n",
      "Input is     print country\n",
      "\n",
      "[torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768])]\n",
      "Raw idx is 38587\n",
      "Raw idx is 128494\n",
      "Raw idx is 139434\n",
      "Raw idx is 135774\n",
      "Raw idx is 44188\n",
      "Raw idx is 472501\n",
      "Raw idx is 168394\n",
      "Raw idx is 486203\n",
      "Raw idx is 487731\n",
      "Raw idx is 487670\n",
      "[cell_type                                                        code\n",
      "source              d = run_length(mask.T.ravel())\\n nmask = {}\\n ...\n",
      "filename                                                     18620591\n",
      "competition                          severstal-steel-defect-detection\n",
      "tokenized_source    [d, =, run_length, (, mask, ., T, ., ravel, (,...\n",
      "Name: 52818, dtype: object, cell_type                                                        code\n",
      "source              # # est. weights\\n \\n # def objective(w, i):\\n...\n",
      "filename                                                     46986735\n",
      "competition                                                  lish-moa\n",
      "tokenized_source    [# # est. weights, [NEWLINE], [NEWLINE], # def...\n",
      "Name: 173710, dtype: object, cell_type                                                        code\n",
      "source              predict = model.predict(test_scaled,num_iterat...\n",
      "filename                                                     39265905\n",
      "competition                        new-york-city-taxi-fare-prediction\n",
      "tokenized_source    [predict, =, model, ., predict, (, test_scaled...\n",
      "Name: 188119, dtype: object, cell_type               code\n",
      "source                      \n",
      "filename            47261563\n",
      "competition         lish-moa\n",
      "tokenized_source          []\n",
      "Name: 183024, dtype: object, cell_type                                                        code\n",
      "source              # IMG_SIZE_ = (1600, 256)\\n IMG_SIZE = (256, 1...\n",
      "filename                                                     21895281\n",
      "competition                          severstal-steel-defect-detection\n",
      "tokenized_source    [# IMG_SIZE_ = (1600, 256), [NEWLINE], [INDENT...\n",
      "Name: 60027, dtype: object, cell_type                                                        code\n",
      "source              # Final check on the new dataset\\n print('Trai...\n",
      "filename                                                     35639945\n",
      "competition                    rsna-intracranial-hemorrhage-detection\n",
      "tokenized_source    [# Final check on the new dataset, [NEWLINE], ...\n",
      "Name: 639575, dtype: object, cell_type                                                        code\n",
      "source              def plot_3d(image, threshold=-300):\\n     \\n  ...\n",
      "filename                                                      1187641\n",
      "competition                                    data-science-bowl-2017\n",
      "tokenized_source    [def, plot_3d, (, image, ,, threshold, =, -, 3...\n",
      "Name: 227355, dtype: object, cell_type                                                        code\n",
      "source              # This Python 3 environment comes with many he...\n",
      "filename                                                     14728664\n",
      "competition         jigsaw-unintended-bias-in-toxicity-classification\n",
      "tokenized_source    [# This Python 3 environment comes with many h...\n",
      "Name: 657104, dtype: object, cell_type                                                        code\n",
      "source              RunningAverage(output_transform=lambda x: x).a...\n",
      "filename                                                     14297703\n",
      "competition         jigsaw-unintended-bias-in-toxicity-classification\n",
      "tokenized_source    [RunningAverage, (, output_transform, =, lambd...\n",
      "Name: 659213, dtype: object, cell_type                                                        code\n",
      "source              def _get_misspell(misspell_dict):\\n     misspe...\n",
      "filename                                                     15401876\n",
      "competition         jigsaw-unintended-bias-in-toxicity-classification\n",
      "tokenized_source                                                   []\n",
      "Name: 659126, dtype: object]\n",
      "############################\n",
      "18620591 severstal-steel-defect-detection\n",
      "############################\n",
      "46986735 lish-moa\n",
      "############################\n",
      "39265905 new-york-city-taxi-fare-prediction\n",
      "############################\n",
      "47261563 lish-moa\n",
      "############################\n",
      "21895281 severstal-steel-defect-detection\n",
      "############################\n",
      "35639945 rsna-intracranial-hemorrhage-detection\n",
      "############################\n",
      "1187641 data-science-bowl-2017\n",
      "############################\n",
      "14728664 jigsaw-unintended-bias-in-toxicity-classification\n",
      "############################\n",
      "14297703 jigsaw-unintended-bias-in-toxicity-classification\n",
      "############################\n",
      "15401876 jigsaw-unintended-bias-in-toxicity-classification\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': ['from __future__ import division\\n', 'import numpy as np\\n', 'from scipy.special import factorial\\n', 'import scipy.stats as stats\\n', 'import pylab\\n', 'import matplotlib.pyplot as plt\\n', '%matplotlib inline\\n', 'import seaborn as sns\\n', 'sns.set_style(\"darkgrid\")\\n', 'import ipywidgets\\n', 'from IPython.display import display\\n', 'from matplotlib.font_manager import FontProperties\\n', 'fontP = FontProperties()\\n', \"fontP.set_size('medium')\\n\", \"%config InlineBackend.figure_format = 'svg'\\n\"]}\n",
      "Input is from __future__ import division\n",
      "\n",
      "Input is import numpy as np\n",
      "\n",
      "Input is from scipy.special import factorial\n",
      "\n",
      "Input is import scipy.stats as stats\n",
      "\n",
      "Input is import pylab\n",
      "\n",
      "Input is import matplotlib.pyplot as plt\n",
      "\n",
      "Input is %matplotlib inline\n",
      "\n",
      "Input is import seaborn as sns\n",
      "\n",
      "Input is sns.set_style(\"darkgrid\")\n",
      "\n",
      "Input is import ipywidgets\n",
      "\n",
      "Input is from IPython.display import display\n",
      "\n",
      "Input is from matplotlib.font_manager import FontProperties\n",
      "\n",
      "Input is fontP = FontProperties()\n",
      "\n",
      "Input is fontP.set_size('medium')\n",
      "\n",
      "Input is %config InlineBackend.figure_format = 'svg'\n",
      "\n",
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': ['\\n', '\\n', 'def mean_firing_rate(gain, stimulus, preferred_stimulus, std_tc, baseline):\\n', '    # Gaussian tuning curve that determines the mean firing rate (Poisson rate parameter) for a given stimulus\\n', '    return baseline + gain*stats.norm.pdf(preferred_stimulus, loc = stimulus, scale = std_tc)\\n', '\\n', 'def get_spikes(gain, stimulus, preferred_stimuli, std_tc, baseline):\\n', '    # produce a vector of spikes for some population given some stimulus\\n', '    lambdas = mean_firing_rate(gain, stimulus, preferred_stimuli, std_tc, baseline)\\n', '    return np.random.poisson(lambdas)\\n', '                \\n', 'def likelihood(stimulus, r, gain, preferred_stimuli, std_tc, baseline):\\n', '    # returns p(r|s)\\n', '    lambdas = mean_firing_rate(gain, stimulus, preferred_stimuli, std_tc, baseline)\\n', '    return np.prod(lambdas**r)\\n', '\\n', 'def spikes_and_inference(r_V = True,\\n', '                         r_A = True,\\n', '                         show_tuning_curves = False,\\n', '                         show_spike_count = False,\\n', '                         show_likelihoods = True,\\n', '                         true_stimulus = 10,\\n', '                         number_of_neurons = 40,\\n', '                         r_V_gain = 15,\\n', '                         r_A_gain = 75,\\n', '                         r_V_tuning_curve_sigma = 10,\\n', '                         r_A_tuning_curve_sigma = 10,\\n', '                         tuning_curve_baseline = 0,\\n', '                         joint_likelihood = True,\\n', '                         r_V_plus_r_A = True,\\n', '                         cue = False):\\n', '    np.random.seed(7)\\n', '    max_s = 40\\n', '    preferred_stimuli = np.linspace(-max_s*2, max_s*2, number_of_neurons)\\n', '    n_hypothesized_s = 250\\n', '    hypothesized_s = np.linspace(-max_s, max_s, n_hypothesized_s)\\n', \"    gains     = {'r1':    r_V_gain,\\n\", \"                 'r2':    r_A_gain,\\n\", \"                 'r1+r2': r_V_gain + r_A_gain}\\n\", \"    sigma_TCs = {'r1':    r_V_tuning_curve_sigma,\\n\", \"                 'r2':    r_A_tuning_curve_sigma,\\n\", \"                 'r1+r2': (r_V_tuning_curve_sigma + r_A_tuning_curve_sigma)/2}\\n\", \"    spikes    = {'r1':    get_spikes(gains['r1'], true_stimulus, preferred_stimuli, sigma_TCs['r1'], tuning_curve_baseline),\\n\", \"                 'r2':    get_spikes(gains['r2'], true_stimulus, preferred_stimuli, sigma_TCs['r2'], tuning_curve_baseline)}\\n\", \"    spikes['r1+r2'] = spikes['r1'] + spikes['r2']\\n\", '    active_pops = []\\n', \"    if r_V: active_pops.append('r1')\\n\", \"    if r_A: active_pops.append('r2')\\n\", \"    if r_V_plus_r_A: active_pops.append('r1+r2')\\n\", '\\n', \"    colors = {'r1':    sns.xkcd_rgb['light purple'],\\n\", \"              'r2':    sns.xkcd_rgb['dark pink'],\\n\", \"              'r1+r2': sns.xkcd_rgb['royal blue'],\\n\", \"              'joint': sns.xkcd_rgb['gold']}\\n\", '    nSubplots = show_spike_count + show_tuning_curves + show_likelihoods\\n', \"    fig, axes = plt.subplots(nSubplots, figsize = (7, 1.5*nSubplots)) # number of subplots according to what's been requested\\n\", \"    if not isinstance(axes, np.ndarray): axes = [axes] # makes axes into a list even if it's just one subplot\\n\", '    subplot_idx = 0\\n', '    \\n', '    def plot_true_stimulus_and_legend(subplot_idx):\\n', \"        axes[subplot_idx].plot(true_stimulus, 0, 'k^', markersize = 12, clip_on = False, label = 'true rattlesnake location')\\n\", \"        axes[subplot_idx].legend(loc = 'center left', bbox_to_anchor = (1, 0.5), prop = fontP)\\n\", '    \\n', '    if show_tuning_curves:\\n', '        for neuron in range(number_of_neurons):\\n', '            if r_V:\\n', '                axes[subplot_idx].plot(hypothesized_s,\\n', \"                                       mean_firing_rate(gains['r1'],\\n\", '                                                        hypothesized_s,\\n', '                                                        preferred_stimuli[neuron],\\n', \"                                                        sigma_TCs['r1'],\\n\", '                                                        tuning_curve_baseline),\\n', \"                                       color = colors['r1'])\\n\", '            if r_A:\\n', '                axes[subplot_idx].plot(hypothesized_s,\\n', \"                                       mean_firing_rate(gains['r2'],\\n\", '                                                        hypothesized_s,\\n', '                                                        preferred_stimuli[neuron],\\n', \"                                                        sigma_TCs['r2'],\\n\", '                                                        tuning_curve_baseline),\\n', \"                                       color = colors['r2'])\\n\", \"        axes[subplot_idx].set_xlabel('location $s$')\\n\", \"        axes[subplot_idx].set_ylabel('mean firing rate\\\\n(spikes/s)')\\n\", '        axes[subplot_idx].set_ylim((0, 4))\\n', '        axes[subplot_idx].set_xlim((-40, 40))\\n', '        axes[subplot_idx].set_yticks(np.linspace(0, 4, 5))\\n', '        subplot_idx += 1\\n']}\n",
      "Input is \n",
      "\n",
      "Input is \n",
      "\n",
      "Input is def mean_firing_rate(gain, stimulus, preferred_stimulus, std_tc, baseline):\n",
      "\n",
      "Input is     # Gaussian tuning curve that determines the mean firing rate (Poisson rate parameter) for a given stimulus\n",
      "\n",
      "Input is     return baseline + gain*stats.norm.pdf(preferred_stimulus, loc = stimulus, scale = std_tc)\n",
      "\n",
      "Input is \n",
      "\n",
      "Input is def get_spikes(gain, stimulus, preferred_stimuli, std_tc, baseline):\n",
      "\n",
      "Input is     # produce a vector of spikes for some population given some stimulus\n",
      "\n",
      "Input is     lambdas = mean_firing_rate(gain, stimulus, preferred_stimuli, std_tc, baseline)\n",
      "\n",
      "Input is     return np.random.poisson(lambdas)\n",
      "\n",
      "Input is                 \n",
      "\n",
      "Input is def likelihood(stimulus, r, gain, preferred_stimuli, std_tc, baseline):\n",
      "\n",
      "Input is     # returns p(r|s)\n",
      "\n",
      "Input is     lambdas = mean_firing_rate(gain, stimulus, preferred_stimuli, std_tc, baseline)\n",
      "\n",
      "Input is     return np.prod(lambdas**r)\n",
      "\n",
      "Input is \n",
      "\n",
      "Input is def spikes_and_inference(r_V = True,\n",
      "\n",
      "Input is                          r_A = True,\n",
      "\n",
      "Input is                          show_tuning_curves = False,\n",
      "\n",
      "Input is                          show_spike_count = False,\n",
      "\n",
      "Input is                          show_likelihoods = True,\n",
      "\n",
      "Input is                          true_stimulus = 10,\n",
      "\n",
      "Input is                          number_of_neurons = 40,\n",
      "\n",
      "Input is                          r_V_gain = 15,\n",
      "\n",
      "Input is                          r_A_gain = 75,\n",
      "\n",
      "Input is                          r_V_tuning_curve_sigma = 10,\n",
      "\n",
      "Input is                          r_A_tuning_curve_sigma = 10,\n",
      "\n",
      "Input is                          tuning_curve_baseline = 0,\n",
      "\n",
      "Input is                          joint_likelihood = True,\n",
      "\n",
      "Input is                          r_V_plus_r_A = True,\n",
      "\n",
      "Input is                          cue = False):\n",
      "\n",
      "Input is     np.random.seed(7)\n",
      "\n",
      "Input is     max_s = 40\n",
      "\n",
      "Input is     preferred_stimuli = np.linspace(-max_s*2, max_s*2, number_of_neurons)\n",
      "\n",
      "Input is     n_hypothesized_s = 250\n",
      "\n",
      "Input is     hypothesized_s = np.linspace(-max_s, max_s, n_hypothesized_s)\n",
      "\n",
      "Input is     gains     = {'r1':    r_V_gain,\n",
      "\n",
      "Input is                  'r2':    r_A_gain,\n",
      "\n",
      "Input is                  'r1+r2': r_V_gain + r_A_gain}\n",
      "\n",
      "Input is     sigma_TCs = {'r1':    r_V_tuning_curve_sigma,\n",
      "\n",
      "Input is                  'r2':    r_A_tuning_curve_sigma,\n",
      "\n",
      "Input is                  'r1+r2': (r_V_tuning_curve_sigma + r_A_tuning_curve_sigma)/2}\n",
      "\n",
      "Input is     spikes    = {'r1':    get_spikes(gains['r1'], true_stimulus, preferred_stimuli, sigma_TCs['r1'], tuning_curve_baseline),\n",
      "\n",
      "Input is                  'r2':    get_spikes(gains['r2'], true_stimulus, preferred_stimuli, sigma_TCs['r2'], tuning_curve_baseline)}\n",
      "\n",
      "Input is     spikes['r1+r2'] = spikes['r1'] + spikes['r2']\n",
      "\n",
      "Input is     active_pops = []\n",
      "\n",
      "Input is     if r_V: active_pops.append('r1')\n",
      "\n",
      "Input is     if r_A: active_pops.append('r2')\n",
      "\n",
      "Input is     if r_V_plus_r_A: active_pops.append('r1+r2')\n",
      "\n",
      "Input is \n",
      "\n",
      "Input is     colors = {'r1':    sns.xkcd_rgb['light purple'],\n",
      "\n",
      "Input is               'r2':    sns.xkcd_rgb['dark pink'],\n",
      "\n",
      "Input is               'r1+r2': sns.xkcd_rgb['royal blue'],\n",
      "\n",
      "Input is               'joint': sns.xkcd_rgb['gold']}\n",
      "\n",
      "Input is     nSubplots = show_spike_count + show_tuning_curves + show_likelihoods\n",
      "\n",
      "Input is     fig, axes = plt.subplots(nSubplots, figsize = (7, 1.5*nSubplots)) # number of subplots according to what's been requested\n",
      "\n",
      "Input is     if not isinstance(axes, np.ndarray): axes = [axes] # makes axes into a list even if it's just one subplot\n",
      "\n",
      "Input is     subplot_idx = 0\n",
      "\n",
      "Input is     \n",
      "\n",
      "Input is     def plot_true_stimulus_and_legend(subplot_idx):\n",
      "\n",
      "Input is         axes[subplot_idx].plot(true_stimulus, 0, 'k^', markersize = 12, clip_on = False, label = 'true rattlesnake location')\n",
      "\n",
      "Input is         axes[subplot_idx].legend(loc = 'center left', bbox_to_anchor = (1, 0.5), prop = fontP)\n",
      "\n",
      "Input is     \n",
      "\n",
      "Input is     if show_tuning_curves:\n",
      "\n",
      "Input is         for neuron in range(number_of_neurons):\n",
      "\n",
      "Input is             if r_V:\n",
      "\n",
      "Input is                 axes[subplot_idx].plot(hypothesized_s,\n",
      "\n",
      "Input is                                        mean_firing_rate(gains['r1'],\n",
      "\n",
      "Input is                                                         hypothesized_s,\n",
      "\n",
      "Input is                                                         preferred_stimuli[neuron],\n",
      "\n",
      "Input is                                                         sigma_TCs['r1'],\n",
      "\n",
      "Input is                                                         tuning_curve_baseline),\n",
      "\n",
      "Input is                                        color = colors['r1'])\n",
      "\n",
      "Input is             if r_A:\n",
      "\n",
      "Input is                 axes[subplot_idx].plot(hypothesized_s,\n",
      "\n",
      "Input is                                        mean_firing_rate(gains['r2'],\n",
      "\n",
      "Input is                                                         hypothesized_s,\n",
      "\n",
      "Input is                                                         preferred_stimuli[neuron],\n",
      "\n",
      "Input is                                                         sigma_TCs['r2'],\n",
      "\n",
      "Input is                                                         tuning_curve_baseline),\n",
      "\n",
      "Input is                                        color = colors['r2'])\n",
      "\n",
      "Input is         axes[subplot_idx].set_xlabel('location $s$')\n",
      "\n",
      "Input is         axes[subplot_idx].set_ylabel('mean firing rate\\n(spikes/s)')\n",
      "\n",
      "Input is         axes[subplot_idx].set_ylim((0, 4))\n",
      "\n",
      "Input is         axes[subplot_idx].set_xlim((-40, 40))\n",
      "\n",
      "Input is         axes[subplot_idx].set_yticks(np.linspace(0, 4, 5))\n",
      "\n",
      "Input is         subplot_idx += 1\n",
      "\n",
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': ['\\n', '    if show_spike_count:\\n', '        idx = abs(preferred_stimuli) < max_s\\n', '        if r_V:\\n', \"            axes[subplot_idx].plot(preferred_stimuli[idx], spikes['r1'][idx], 'o', color = colors['r1'],\\n\", \"                                   clip_on = False,  label = '$\\\\mathbf{r}_\\\\mathrm{V}$',\\n\", '                                   markersize=4)\\n', '        if r_A:\\n', \"            axes[subplot_idx].plot(preferred_stimuli[idx], spikes['r2'][idx], 'o', color = colors['r2'],\\n\", \"                                   clip_on = False, label = '$\\\\mathbf{r}_\\\\mathrm{A}$',\\n\", '                                   markersize=4)\\n', '        if r_V_plus_r_A:\\n', \"            axes[subplot_idx].plot(preferred_stimuli[idx], spikes['r1+r2'][idx], 'o', color = colors['r1+r2'],\\n\", \"                                   clip_on = False, label = '$\\\\mathbf{r}_\\\\mathrm{V}+\\\\mathbf{r}_\\\\mathrm{A}$',\\n\", '                                   markersize=8, zorder=1)\\n', \"        axes[subplot_idx].set_xlabel('preferred location')\\n\", \"        axes[subplot_idx].set_ylabel('spike count')\\n\", '        axes[subplot_idx].set_ylim((0, 10))\\n', '        axes[subplot_idx].set_xlim((-40, 40))\\n', '        plot_true_stimulus_and_legend(subplot_idx)\\n', '        subplot_idx += 1\\n', '\\n']}\n",
      "Input is \n",
      "\n",
      "Input is     if show_spike_count:\n",
      "\n",
      "Input is         idx = abs(preferred_stimuli) < max_s\n",
      "\n",
      "Input is         if r_V:\n",
      "\n",
      "Input is             axes[subplot_idx].plot(preferred_stimuli[idx], spikes['r1'][idx], 'o', color = colors['r1'],\n",
      "\n",
      "Input is                                    clip_on = False,  label = '$\\mathbf{r}_\\mathrm{V}$',\n",
      "\n",
      "Input is                                    markersize=4)\n",
      "\n",
      "Input is         if r_A:\n",
      "\n",
      "Input is             axes[subplot_idx].plot(preferred_stimuli[idx], spikes['r2'][idx], 'o', color = colors['r2'],\n",
      "\n",
      "Input is                                    clip_on = False, label = '$\\mathbf{r}_\\mathrm{A}$',\n",
      "\n",
      "Input is                                    markersize=4)\n",
      "\n",
      "Input is         if r_V_plus_r_A:\n",
      "\n",
      "Input is             axes[subplot_idx].plot(preferred_stimuli[idx], spikes['r1+r2'][idx], 'o', color = colors['r1+r2'],\n",
      "\n",
      "Input is                                    clip_on = False, label = '$\\mathbf{r}_\\mathrm{V}+\\mathbf{r}_\\mathrm{A}$',\n",
      "\n",
      "Input is                                    markersize=8, zorder=1)\n",
      "\n",
      "Input is         axes[subplot_idx].set_xlabel('preferred location')\n",
      "\n",
      "Input is         axes[subplot_idx].set_ylabel('spike count')\n",
      "\n",
      "Input is         axes[subplot_idx].set_ylim((0, 10))\n",
      "\n",
      "Input is         axes[subplot_idx].set_xlim((-40, 40))\n",
      "\n",
      "Input is         plot_true_stimulus_and_legend(subplot_idx)\n",
      "\n",
      "Input is         subplot_idx += 1\n",
      "\n",
      "Input is \n",
      "\n",
      "{'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': ['    if show_likelihoods:\\n', '        if cue:\\n', \"            var = 'c'\\n\", '        else:\\n', \"            var = '\\\\mathbf{r}'\\n\", '        likelihoods = {}\\n', '            \\n', '        for population in active_pops:\\n', '            likelihoods[population] = np.zeros_like(hypothesized_s)\\n', '            for idx, ort in enumerate(hypothesized_s):\\n', '                likelihoods[population][idx] = likelihood(ort, spikes[population], gains[population],\\n', '                                                          preferred_stimuli, sigma_TCs[population], tuning_curve_baseline)\\n', '            likelihoods[population] /= np.sum(likelihoods[population]) # normalize\\n', '\\n', '        if r_V:\\n', \"            axes[subplot_idx].plot(hypothesized_s, likelihoods['r1'], color = colors['r1'],\\n\", \"                                   linewidth = 2, label = '$p({}_\\\\mathrm{{V}}|s)$'.format(var))\\n\", '        if r_A:\\n', \"            axes[subplot_idx].plot(hypothesized_s, likelihoods['r2'], color = colors['r2'],\\n\", \"                                   linewidth = 2, label = '$p({}_\\\\mathrm{{A}}|s)$'.format(var))\\n\", '        if r_V_plus_r_A:\\n', \"            axes[subplot_idx].plot(hypothesized_s, likelihoods['r1+r2'], color = colors['r1+r2'],\\n\", \"                                   linewidth = 2, label = '$p({}_\\\\mathrm{{V}}+{}_\\\\mathrm{{A}}|s)$'.format(var, var))\\n\", '        if joint_likelihood:\\n', \"            product = likelihoods['r1']*likelihoods['r2']\\n\", '            product /= np.sum(product)\\n', \"            axes[subplot_idx].plot(hypothesized_s, product, color = colors['joint'],linewidth = 7,\\n\", \"                                   label = '$p({}_\\\\mathrm{{V}}|s)\\\\ p({}_\\\\mathrm{{A}}|s)$'.format(var, var), zorder = 1)\\n\", '\\n', \"        axes[subplot_idx].set_xlabel('location $s$')\\n\", \"        axes[subplot_idx].set_ylabel('probability')\\n\", '        axes[subplot_idx].set_xlim((-40, 40))\\n', '        axes[subplot_idx].legend()\\n', '        axes[subplot_idx].set_yticks([])\\n', '        \\n', '        plot_true_stimulus_and_legend(subplot_idx)\\n', '        subplot_idx += 1\\n']}\n",
      "Input is     if show_likelihoods:\n",
      "\n",
      "Input is         if cue:\n",
      "\n",
      "Input is             var = 'c'\n",
      "\n",
      "Input is         else:\n",
      "\n",
      "Input is             var = '\\mathbf{r}'\n",
      "\n",
      "Input is         likelihoods = {}\n",
      "\n",
      "Input is             \n",
      "\n",
      "Input is         for population in active_pops:\n",
      "\n",
      "Input is             likelihoods[population] = np.zeros_like(hypothesized_s)\n",
      "\n",
      "Input is             for idx, ort in enumerate(hypothesized_s):\n",
      "\n",
      "Input is                 likelihoods[population][idx] = likelihood(ort, spikes[population], gains[population],\n",
      "\n",
      "Input is                                                           preferred_stimuli, sigma_TCs[population], tuning_curve_baseline)\n",
      "\n",
      "Input is             likelihoods[population] /= np.sum(likelihoods[population]) # normalize\n",
      "\n",
      "Input is \n",
      "\n",
      "Input is         if r_V:\n",
      "\n",
      "Input is             axes[subplot_idx].plot(hypothesized_s, likelihoods['r1'], color = colors['r1'],\n",
      "\n",
      "Input is                                    linewidth = 2, label = '$p({}_\\mathrm{{V}}|s)$'.format(var))\n",
      "\n",
      "Input is         if r_A:\n",
      "\n",
      "Input is             axes[subplot_idx].plot(hypothesized_s, likelihoods['r2'], color = colors['r2'],\n",
      "\n",
      "Input is                                    linewidth = 2, label = '$p({}_\\mathrm{{A}}|s)$'.format(var))\n",
      "\n",
      "Input is         if r_V_plus_r_A:\n",
      "\n",
      "Input is             axes[subplot_idx].plot(hypothesized_s, likelihoods['r1+r2'], color = colors['r1+r2'],\n",
      "\n",
      "Input is                                    linewidth = 2, label = '$p({}_\\mathrm{{V}}+{}_\\mathrm{{A}}|s)$'.format(var, var))\n",
      "\n",
      "Input is         if joint_likelihood:\n",
      "\n",
      "Input is             product = likelihoods['r1']*likelihoods['r2']\n",
      "\n",
      "Input is             product /= np.sum(product)\n",
      "\n",
      "Input is             axes[subplot_idx].plot(hypothesized_s, product, color = colors['joint'],linewidth = 7,\n",
      "\n",
      "Input is                                    label = '$p({}_\\mathrm{{V}}|s)\\ p({}_\\mathrm{{A}}|s)$'.format(var, var), zorder = 1)\n",
      "\n",
      "Input is \n",
      "\n",
      "Input is         axes[subplot_idx].set_xlabel('location $s$')\n",
      "\n",
      "Input is         axes[subplot_idx].set_ylabel('probability')\n",
      "\n",
      "Input is         axes[subplot_idx].set_xlim((-40, 40))\n",
      "\n",
      "Input is         axes[subplot_idx].legend()\n",
      "\n",
      "Input is         axes[subplot_idx].set_yticks([])\n",
      "\n",
      "Input is         \n",
      "\n",
      "Input is         plot_true_stimulus_and_legend(subplot_idx)\n",
      "\n",
      "Input is         subplot_idx += 1\n",
      "\n",
      "[torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768])]\n",
      "Raw idx is 38587\n",
      "Raw idx is 128494\n",
      "Raw idx is 135774\n",
      "Raw idx is 139434\n",
      "Raw idx is 168394\n",
      "Raw idx is 168496\n",
      "Raw idx is 487670\n",
      "Raw idx is 486203\n",
      "Raw idx is 487731\n",
      "Raw idx is 592002\n",
      "[cell_type                                                        code\n",
      "source              d = run_length(mask.T.ravel())\\n nmask = {}\\n ...\n",
      "filename                                                     18620591\n",
      "competition                          severstal-steel-defect-detection\n",
      "tokenized_source    [d, =, run_length, (, mask, ., T, ., ravel, (,...\n",
      "Name: 52818, dtype: object, cell_type                                                        code\n",
      "source              # # est. weights\\n \\n # def objective(w, i):\\n...\n",
      "filename                                                     46986735\n",
      "competition                                                  lish-moa\n",
      "tokenized_source    [# # est. weights, [NEWLINE], [NEWLINE], # def...\n",
      "Name: 173710, dtype: object, cell_type               code\n",
      "source                      \n",
      "filename            47261563\n",
      "competition         lish-moa\n",
      "tokenized_source          []\n",
      "Name: 183024, dtype: object, cell_type                                                        code\n",
      "source              predict = model.predict(test_scaled,num_iterat...\n",
      "filename                                                     39265905\n",
      "competition                        new-york-city-taxi-fare-prediction\n",
      "tokenized_source    [predict, =, model, ., predict, (, test_scaled...\n",
      "Name: 188119, dtype: object, cell_type                                                        code\n",
      "source              def plot_3d(image, threshold=-300):\\n     \\n  ...\n",
      "filename                                                      1187641\n",
      "competition                                    data-science-bowl-2017\n",
      "tokenized_source    [def, plot_3d, (, image, ,, threshold, =, -, 3...\n",
      "Name: 227355, dtype: object, cell_type                                                        code\n",
      "source              %matplotlib inline\\n \\n import numpy as np # l...\n",
      "filename                                                       917264\n",
      "competition                                    data-science-bowl-2017\n",
      "tokenized_source    [%, matplotlib, inline, [NEWLINE], [NEWLINE], ...\n",
      "Name: 227512, dtype: object, cell_type                                                        code\n",
      "source              def _get_misspell(misspell_dict):\\n     misspe...\n",
      "filename                                                     15401876\n",
      "competition         jigsaw-unintended-bias-in-toxicity-classification\n",
      "tokenized_source                                                   []\n",
      "Name: 659126, dtype: object, cell_type                                                        code\n",
      "source              # This Python 3 environment comes with many he...\n",
      "filename                                                     14728664\n",
      "competition         jigsaw-unintended-bias-in-toxicity-classification\n",
      "tokenized_source    [# This Python 3 environment comes with many h...\n",
      "Name: 657104, dtype: object, cell_type                                                        code\n",
      "source              RunningAverage(output_transform=lambda x: x).a...\n",
      "filename                                                     14297703\n",
      "competition         jigsaw-unintended-bias-in-toxicity-classification\n",
      "tokenized_source    [RunningAverage, (, output_transform, =, lambd...\n",
      "Name: 659213, dtype: object, cell_type                                                        code\n",
      "source              IDS = []\\n labels = []\\n \\n for label in ['neg...\n",
      "filename                                                     42907330\n",
      "competition                     rsna-str-pulmonary-embolism-detection\n",
      "tokenized_source    [IDS, =, [, ], [NEWLINE], [INDENT], labels, =,...\n",
      "Name: 800557, dtype: object]\n",
      "############################\n",
      "18620591 severstal-steel-defect-detection\n",
      "############################\n",
      "46986735 lish-moa\n",
      "############################\n",
      "47261563 lish-moa\n",
      "############################\n",
      "39265905 new-york-city-taxi-fare-prediction\n",
      "############################\n",
      "1187641 data-science-bowl-2017\n",
      "############################\n",
      "917264 data-science-bowl-2017\n",
      "############################\n",
      "15401876 jigsaw-unintended-bias-in-toxicity-classification\n",
      "############################\n",
      "14728664 jigsaw-unintended-bias-in-toxicity-classification\n",
      "############################\n",
      "14297703 jigsaw-unintended-bias-in-toxicity-classification\n",
      "############################\n",
      "42907330 rsna-str-pulmonary-embolism-detection\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7104ee2c7f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Update the sample.py and press Enter to continue...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;31m# TODO: reads ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./sample.ipynb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smarteda/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             )\n\u001b[0;32m--> 848\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smarteda/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import BertModel, Generator\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "from pathlib import Path\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from tokenize_code import tokenize_code\n",
    "\n",
    "from utils import CellFeatures, InputFeatures, convert_examples_to_features, parseNotebook, get_notebook_list, get_embedding\n",
    "from config import *\n",
    "\n",
    "class RetrivalDB:\n",
    "  def __init__(self):\n",
    "    doc2vec_path = '../doc2vec/model'\n",
    "    self.embed = np.asarray(embeds1d)\n",
    "    self.df = data\n",
    "    self.df = self.df[self.df.cell_type == 'code']\n",
    "    # self.kernel_ids = np.load(doc2vec_path + \"codebase_doc2vec_id.npy\", allow_pickle=True)\n",
    "\n",
    "  def getDoc(self, raw_idx):\n",
    "    print(\"Raw idx is\", raw_idx)\n",
    "    if raw_idx < 0 or raw_idx >= self.embed.shape[0]:\n",
    "      print(\"ERROR: out of index\")\n",
    "      return None\n",
    "    \n",
    "    return self.df.iloc[raw_idx]\n",
    "\n",
    "  def find_sim(self, embed, topn=10):\n",
    "    result = np.einsum(\"ij,ij->i\",self.embed,embed)\n",
    "    rank = np.argsort(-result)[:topn]\n",
    "    doc_list = [self.getDoc(r) for r in rank]\n",
    "    return doc_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  # TODO: change to doc2vec\n",
    "  doc2vec_path = '../doc2vec/model'\n",
    "  model = Doc2Vec.load(doc2vec_path + \"/notebook-doc2vec-model-apr24.model\")\n",
    "\n",
    "  # gen = torch.load(doc2vec_path + \"/best_gen.pt\").to(device)\n",
    "  gen = Generator(768, 768).to(device)\n",
    "  gen = torch.load('gen_saved/best_gen.pt')\n",
    "  gen.eval()\n",
    "  db = RetrivalDB()\n",
    "  \n",
    "  while(True):\n",
    "    print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "    input(\"Update the sample.py and press Enter to continue...\")\n",
    "    # TODO: reads ipynb\n",
    "    input_file = './sample.ipynb'\n",
    "    embed_list = []\n",
    "    f = codecs.open(input_file, 'r')\n",
    "    source = f.read()\n",
    "\n",
    "    y = json.loads(source)\n",
    "    for x in y['cells']:\n",
    "        print(x)\n",
    "        for x2 in x['source']:\n",
    "            if x2[-1] != '\\n':\n",
    "                x2 = x2 + '\\n'\n",
    "            print(\"Input is\", x2)\n",
    "            embed_list.append(torch.Tensor(model.infer_vector(tokenize_code(x2,'code'))).to(device))\n",
    "\n",
    "    print([e.shape for e in embed_list])\n",
    "\n",
    "    predict_embed = gen.generate_embedding(embed_list)\n",
    "\n",
    "    predict_embed = [embed.detach().cpu().numpy() for embed in predict_embed]\n",
    "    \n",
    "    doc_list = db.find_sim(predict_embed, topn=10)\n",
    "    print(doc_list)\n",
    "    file_path = '../doc2vec/data/sliced-notebooks-full-new'\n",
    "\n",
    "    for col in doc_list:\n",
    "#       print(col)\n",
    "      print(\"############################\")\n",
    "      print(col.filename, col.competition)\n",
    "      #print(col.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distant-filing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gru_unit): GRU(768, 768)\n",
       "  (trans): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.load('gen_saved/best_gen.pt')\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "common-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"gen_saved/doc2vec_best_gen.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
