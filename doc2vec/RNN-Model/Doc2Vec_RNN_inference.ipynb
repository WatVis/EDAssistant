{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latin-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../doc2vec/data/smalldf-1000notebooks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data.cell_type==\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "necessary-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeds2d = np.load(\"../doc2vec/data/notebooks-sliced-doc2vec-vectors-apr7-small.npy\",allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elect-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds1d = []\n",
    "for row in embeds2d:\n",
    "    for vecs in row:\n",
    "        embeds1d.append(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assigned-coordinator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22303"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeds1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is import pandas as pd\n",
      "\n",
      "Input is df = pd.read_csv('1.csv')\n",
      "\n",
      "Input is df.head()\n",
      "\n",
      "[torch.Size([768]), torch.Size([768]), torch.Size([768])]\n",
      "Raw idx is 19602\n",
      "Raw idx is 19016\n",
      "Raw idx is 20519\n",
      "############################\n",
      "35082405 tweet-sentiment-extraction\n",
      "## now do the same for selected text\n",
      " selected_shap_extracted = []\n",
      " for i in np.arange(len(df_train)):\n",
      "     selected_shap_extracted.append(shap_values[i, df_train['selected_text_word_index'][i]])\n",
      "############################\n",
      "6186489 ga-customer-revenue-prediction\n",
      "# Extract target values and Ids\n",
      " cat_cols = ['channelGrouping','device.browser',\n",
      "        'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\n",
      "        'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\n",
      "        'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.\n",
      "############################\n",
      "7237023 pubg-finish-placement-prediction\n",
      "corr = train_df[['walkDistance', 'players_in_team','total_kickass_score', 'winPlacePerc']].corr()\n",
      " sns.heatmap(\n",
      "     corr,\n",
      "     xticklabels=corr.columns.values,\n",
      "     yticklabels=corr.columns.values,\n",
      "     linecolor='white',\n",
      "     linewidths=0.1,\n",
      "     cmap=\"RdBu\"\n",
      " )\n",
      " plt.show()\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import BertModel, Generator\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "from pathlib import Path\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from utils import CellFeatures, InputFeatures, convert_examples_to_features, parseNotebook, get_notebook_list, get_embedding\n",
    "from config import *\n",
    "\n",
    "class RetrivalDB:\n",
    "  def __init__(self):\n",
    "    doc2vec_path = '../doc2vec/model'\n",
    "    self.embed = np.asarray(embeds1d)\n",
    "    self.df = pd.read_csv(\"../doc2vec/data/smalldf-1000notebooks.csv\")\n",
    "    self.df = self.df[self.df.cell_type == 'code']\n",
    "    # self.kernel_ids = np.load(doc2vec_path + \"codebase_doc2vec_id.npy\", allow_pickle=True)\n",
    "\n",
    "  def getDoc(self, raw_idx):\n",
    "    print(\"Raw idx is\", raw_idx)\n",
    "    if raw_idx < 0 or raw_idx >= self.embed.shape[0]:\n",
    "      print(\"ERROR: out of index\")\n",
    "      return None\n",
    "    \n",
    "    return self.df.iloc[raw_idx]\n",
    "\n",
    "  def find_sim(self, embed, topn=10):\n",
    "    result = np.einsum(\"ij,ij->i\",self.embed,embed)\n",
    "    rank = np.argsort(-result)[:topn]\n",
    "    doc_list = [self.getDoc(r) for r in rank]\n",
    "    return doc_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  # TODO: change to doc2vec\n",
    "  doc2vec_path = '../doc2vec/model'\n",
    "  model = Doc2Vec.load(doc2vec_path + \"/notebook-doc2vec-model-apr7-1000notebooks.model\")\n",
    "\n",
    "  # gen = torch.load(doc2vec_path + \"/best_gen.pt\").to(device)\n",
    "  gen = Generator(768, 768).to(device)\n",
    "  gen = torch.load('gen_saved/best_gen.pt')\n",
    "  gen.eval()\n",
    "  db = RetrivalDB()\n",
    "  \n",
    "  while(True):\n",
    "    print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "    input(\"Update the sample.py and press Enter to continue...\")\n",
    "    # TODO: reads ipynb\n",
    "    input_file = './sample.ipynb'\n",
    "    embed_list = []\n",
    "    f = codecs.open(input_file, 'r')\n",
    "    source = f.read()\n",
    "\n",
    "    y = json.loads(source)\n",
    "    for x in y['cells']:\n",
    "        for x2 in x['source']:\n",
    "            if x2[-1] != '\\n':\n",
    "                x2 = x2 + '\\n'\n",
    "            print(\"Input is\", x2)\n",
    "            embed_list.append(torch.Tensor(model.infer_vector(x2.split(' '))).to(device))\n",
    "\n",
    "    print([e.shape for e in embed_list])\n",
    "\n",
    "    predict_embed = gen.generate_embedding(embed_list)\n",
    "\n",
    "    predict_embed = [embed.detach().cpu().numpy() for embed in predict_embed]\n",
    "\n",
    "    doc_list = db.find_sim(predict_embed, topn=3)\n",
    "\n",
    "    file_path = '../doc2vec/data/sliced-notebooks-full-new'\n",
    "\n",
    "    for col in doc_list:\n",
    "#       print(col)\n",
    "      print(\"############################\")\n",
    "      print(col.filename, col.competition)\n",
    "      print(col.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broke-entrance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gru_unit): GRU(768, 768)\n",
       "  (trans): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.load('gen_saved/best_gen.pt')\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specialized-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"gen_saved/doc2vec_best_gen.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
