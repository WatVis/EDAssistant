{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Dataset into Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to generate a vector for each cell for all notebooks in the sliced-notebooks dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions of vector array: n * sequence count * 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import torch\n",
    "from tokenize_code import tokenize_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset and doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/all-notebooks-tokenized.json\", orient='index')\n",
    "model = Doc2Vec.load(\"../model/notebook-doc2vec-model-apr24.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.cell_type == \"code\"]\n",
    "df['cell_num'] = df.groupby(['competition','filename']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cell_type', 'source', 'filename', 'competition', 'tokenized_source',\n",
       "       'cell_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group the dataset by notebook and generate doc2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cell_type', 'source', 'filename', 'competition', 'tokenized_source',\n",
       "       'cell_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allVectors = []\n",
    "allVectorsFilenames = []\n",
    "for i, notebook in df_test.groupby(\"filename\"):\n",
    "    \n",
    "    vectorSeq = []\n",
    "    vectorNameSeq = []\n",
    "    # vectorSeq is a list of doc2vec vectors corresponding to [Cell0, Cell1, .... Celln]\n",
    "    # each vectorSeq list corresponds to a single notebook\n",
    "    for j, row in notebook.iterrows():\n",
    "        #print(row)\n",
    "        competition = row[3]\n",
    "        cell_num = row[5]\n",
    "        tokenized_source = row[4]\n",
    "        kernel_id = row[2]\n",
    "        \n",
    "        source = row[1]\n",
    "        vector = model.infer_vector(tokenized_source)\n",
    "        vectorSeq.append(vector)\n",
    "        vectorNameSeq.append(notebook.iloc[0]['competition'] + \"/\" + notebook.iloc[0]['filename'].astype(str) + \"_\" + str(cell_num))\n",
    "    allVectors.append(vectorSeq)\n",
    "    allVectorsFilenames.append(vectorNameSeq)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from lists of arrays to array of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,A.shape[0]):\n",
    "    A[i] = np.asarray(A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38086\n"
     ]
    }
   ],
   "source": [
    "print(len(allVectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(allVectors,dtype=object)\n",
    "arrNames = np.array(allVectorsFilenames, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrNames[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/notebooks-doc2vec-vectors-apr24.npy\", arr)\n",
    "np.save(\"../data/notebooks-doc2vec-vectors-filenames-apr24.npy\", arrNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
