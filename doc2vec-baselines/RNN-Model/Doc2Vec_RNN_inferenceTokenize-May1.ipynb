{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-berry",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ashrae-energy-prediction\\\\25644298_5', 1), ('ashrae-energy-prediction\\\\25840661_5', 1), ('ashrae-energy-prediction\\\\25644298_6', 1), ('ashrae-energy-prediction\\\\25644298_3', 1), ('ashrae-energy-prediction\\\\25644298_2', 1), ('ashrae-energy-prediction\\\\25644298_0', 1), ('ashrae-energy-prediction\\\\25840661_6', 1), ('ashrae-energy-prediction\\\\25644298_1', 1), ('ashrae-energy-prediction\\\\25644298_4', 1), ('ashrae-energy-prediction\\\\25840885_4', 1)]\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quora-insincere-questions-classification\\\\8544113_3', 1), ('ashrae-energy-prediction\\\\25644298_5', 1), ('ashrae-energy-prediction\\\\25644298_6', 1), ('ashrae-energy-prediction\\\\25840661_5', 1), ('quora-insincere-questions-classification\\\\8544113_4', 2), ('quora-insincere-questions-classification\\\\8544113_5', 2), ('ashrae-energy-prediction\\\\25644298_0', 1), ('ashrae-energy-prediction\\\\25840661_6', 1), ('ashrae-energy-prediction\\\\25644298_2', 1), ('ashrae-energy-prediction\\\\25644298_3', 1)]\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('siim-isic-melanoma-classification\\\\41020093_5', 0), ('siim-isic-melanoma-classification\\\\41020093_4', 0), ('siim-isic-melanoma-classification\\\\38159585_0', 0), ('siim-isic-melanoma-classification\\\\38159585_4', 0), ('siim-isic-melanoma-classification\\\\41020093_2', 0), ('siim-isic-melanoma-classification\\\\41020093_3', 0), ('siim-isic-melanoma-classification\\\\38159585_1', 0), ('siim-isic-melanoma-classification\\\\38159585_2', 0), ('siim-isic-melanoma-classification\\\\41020093_0', 0), ('siim-isic-melanoma-classification\\\\38159585_3', 0)]\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Update the sample.py and press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quora-insincere-questions-classification\\\\8544113_3', 1), ('quora-insincere-questions-classification\\\\8544113_4', 2), ('quora-insincere-questions-classification\\\\8544113_5', 2), ('quora-insincere-questions-classification\\\\8544113_10', 2), ('quora-insincere-questions-classification\\\\8544113_9', 2), ('quora-insincere-questions-classification\\\\8544113_11', 2), ('kobe-bryant-shot-selection\\\\1890199_49', 1), ('ashrae-energy-prediction\\\\25644298_5', 1), ('ashrae-energy-prediction\\\\25840661_5', 1), ('ashrae-energy-prediction\\\\25644298_6', 1)]\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import BertModel, Generator\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, \\\n",
    "    RandomSampler, TensorDataset\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "from pathlib import Path\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from utils import CellFeatures, InputFeatures, \\\n",
    "    convert_examples_to_features, parseNotebook, get_notebook_list, \\\n",
    "    get_embedding\n",
    "from config import *\n",
    "\n",
    "from tokenize_code import tokenize_code\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "\n",
    "class RetrivalDB:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.embed = np.load('embed_tensors_clean_apr29.npy',\n",
    "                             allow_pickle=True)\n",
    "        self.kernel_ids = np.load('kernel_ids_apr29.npy',\n",
    "                                  allow_pickle=True)\n",
    "        self.idx_list = []\n",
    "        idx = 0\n",
    "        doc_list = []\n",
    "        for doc in self.embed:\n",
    "            self.idx_list.append(idx)\n",
    "            idx += doc.shape[0]\n",
    "            doc_list.append(doc)\n",
    "        self.raw = np.concatenate(doc_list)\n",
    "\n",
    "    def getDoc(self, raw_idx):\n",
    "        if raw_idx < 0 or raw_idx >= self.raw.shape[0]:\n",
    "            print('ERROR: out of index')\n",
    "            return None\n",
    "        first = 0\n",
    "        last = len(self.idx_list) - 1\n",
    "        midpoint = (first + last) // 2\n",
    "        while True:\n",
    "            midpoint = (first + last) // 2\n",
    "            if self.idx_list[midpoint] <= raw_idx \\\n",
    "                and self.idx_list[midpoint + 1] > raw_idx:\n",
    "                break\n",
    "            else:\n",
    "                if raw_idx < self.idx_list[midpoint]:\n",
    "                    last = midpoint - 1\n",
    "                else:\n",
    "                    first = midpoint + 1\n",
    "        kernel_id = self.kernel_ids[midpoint]\n",
    "        return (kernel_id, raw_idx - self.idx_list[midpoint])\n",
    "\n",
    "    def find_sim(self, embed, topn=10):\n",
    "        result = np.einsum('ij,ij->i', self.raw, embed)\n",
    "        rank = np.argsort(-result)[:topn]\n",
    "        doc_list = [self.getDoc(r) for r in rank]\n",
    "        return doc_list\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Load the RNN model\n",
    "    gen = torch.load('./gen_saved/best_gen.pt').to(device)\n",
    "    gen.eval()\n",
    "    \n",
    "    # Load the doc2vec model\n",
    "    model = Doc2Vec.load(\"../doc2vec/model/notebook-doc2vec-model-apr24.model\")\n",
    "    db = RetrivalDB()\n",
    "\n",
    "    while True:\n",
    "        print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "        input('Update the sample.py and press Enter to continue...')\n",
    "\n",
    "        # TODO: reads ipynb\n",
    "\n",
    "        input_file = './sample.ipynb'\n",
    "        embed_list = []\n",
    "        f = codecs.open(input_file, 'r')\n",
    "        source = f.read()\n",
    "\n",
    "        y = json.loads(source)\n",
    "        for x in y['cells']:\n",
    "    #         print(x) \n",
    "            for x2 in x['source']:\n",
    "                if x2[-1] != '\\n':\n",
    "                    x2 = x2 + '\\n'\n",
    "    #             print(\"Input is\", x2)\n",
    "                embed_list.append(torch.Tensor(model.infer_vector(tokenize_code(x2,'code'))).to(device))\n",
    "        #print([e.shape for e in embed_list])\n",
    "        predict_embed = gen.generate_embedding(embed_list)\n",
    "        predict_embed = [embed.detach().cpu().numpy() for embed in predict_embed]\n",
    "        \n",
    "        doc_list = db.find_sim(predict_embed, topn=10)\n",
    "        print(doc_list)\n",
    "        file_path = '../doc2vec/data/sliced-notebooks-full-new'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
