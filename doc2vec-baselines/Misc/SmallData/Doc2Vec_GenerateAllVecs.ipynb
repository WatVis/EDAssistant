{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solar-moscow",
   "metadata": {},
   "source": [
    "# Convert the Dataset into Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-cricket",
   "metadata": {},
   "source": [
    "The goal of this notebook is to generate a vector for each cell for all notebooks in the sliced-notebooks dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-check",
   "metadata": {},
   "source": [
    "Dimensions of vector array: n * sequence count * 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-debate",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "endless-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-virgin",
   "metadata": {},
   "source": [
    "# Import dataset and doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identical-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/smalldf-1000notebooks.csv\")\n",
    "model = Doc2Vec.load(\"../model/notebook-doc2vec-model-apr7-1000notebooks.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cutting-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.cell_type == \"code\"]\n",
    "df['cell_num'] = df.groupby(['competition','filename']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impossible-salad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22303"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-quality",
   "metadata": {},
   "source": [
    "# Group the dataset by notebook and generate doc2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sudden-disco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'cell_type', 'source', 'filename', 'competition',\n",
       "       'cell_num', 'filename_with_cellnum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "turned-protest",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allVectors = []\n",
    "allVectorsFilenames = []\n",
    "for i, notebook in df_test.groupby(\"filename\"):\n",
    "    \n",
    "    vectorSeq = []\n",
    "    vectorNameSeq = []\n",
    "    # vectorSeq is a list of doc2vec vectors corresponding to [Cell0, Cell1, .... Celln]\n",
    "    # each vectorSeq list corresponds to a single notebook\n",
    "    for j, row in notebook.iterrows():\n",
    "        \n",
    "        competition = row[3]\n",
    "        cell_num = row[4]\n",
    "        kernel_id = row[2]\n",
    "        \n",
    "        source = row[1]\n",
    "        vector = model.infer_vector(source.split(\" \"))\n",
    "        vectorSeq.append(vector)\n",
    "        vectorNameSeq.append(notebook.iloc[0]['competition'] + \"/\" + notebook.iloc[0]['filename'].astype(str) + \"_\" + str(cell_num))\n",
    "    allVectors.append(vectorSeq)\n",
    "    allVectorsFilenames.append(vectorNameSeq)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-cricket",
   "metadata": {},
   "source": [
    "## Convert from lists of arrays to array of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "right-mercury",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d741e380eedb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0,A.shape[0]):\n",
    "    A[i] = np.asarray(A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dangerous-space",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38086\n"
     ]
    }
   ],
   "source": [
    "print(len(allVectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-overall",
   "metadata": {},
   "source": [
    "# Save the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cooked-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(allVectors,dtype=object)\n",
    "arrNames = np.array(allVectorsFilenames, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coral-lewis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion',\n",
       " 'homesite-quote-conversion/153081_homesite-quote-conversion']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrNames[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "diagnostic-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/notebooks-sliced-doc2vec-vectors-apr7-small.npy\", arr)\n",
    "np.save(\"../data/notebooks-sliced-doc2vec-vectors-filenames-apr7-small.npy\", arrNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-discharge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
